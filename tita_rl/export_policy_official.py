import os
import subprocess
import argparse

# CRITICAL: isaacgym å¿…é¡»åœ¨ torch ä¹‹å‰å¯¼å…¥
import isaacgym

from global_config import ROOT_DIR
from envs import *
from utils import get_args, task_registry, get_load_path, class_to_dict
from modules import ActorCritic, ActorCriticRecurrent, ActorCriticRMA, ActorCriticBarlowTwins
import torch
import copy


def export_policy_as_onnx(args, pt_path=None, output_path=None, convert_engine=False):
    """
    å¯¼å‡ºç­–ç•¥ä¸º ONNX æ ¼å¼
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        pt_path: æŒ‡å®šçš„ PT æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œä¼˜å…ˆä½¿ç”¨è¿™ä¸ªï¼‰
        output_path: è¾“å‡º ONNX æ–‡ä»¶è·¯å¾„
        convert_engine: æ˜¯å¦è½¬æ¢ä¸º TensorRT engine
    """
    # è·å–é…ç½®
    env_cfg, train_cfg = task_registry.get_cfgs(name=args.task)
    
    print("=" * 70)
    print(f"ä»»åŠ¡: {args.task}")
    print(f"ç­–ç•¥ç±»: {train_cfg.runner.policy_class_name}")
    print("=" * 70)
    
    # ç¡®å®šæ¨¡å‹è·¯å¾„
    if pt_path and os.path.exists(pt_path):
        resume_path = pt_path
        print(f"âœ“ ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹: {resume_path}")
    else:
        log_root = os.path.join(ROOT_DIR, 'logs', train_cfg.runner.experiment_name)
        resume_path = get_load_path(
            log_root, 
            load_run=train_cfg.runner.load_run, 
            checkpoint=train_cfg.runner.checkpoint
        )
        print(f"âœ“ ä»æ—¥å¿—åŠ è½½æ¨¡å‹: {resume_path}")
    
    # åŠ è½½æ¨¡å‹
    print(f"\nğŸ“‚ åŠ è½½æ¨¡å‹æ–‡ä»¶...")
    loaded_dict = torch.load(resume_path, map_location='cpu')
    
    # è·å–ç­–ç•¥ç±»
    actor_critic_class = eval(train_cfg.runner.policy_class_name)
    
    # è®¾ç½®ç‰¹æƒè§‚æµ‹ç»´åº¦
    if env_cfg.env.num_privileged_obs is None:
        env_cfg.env.num_privileged_obs = env_cfg.env.num_propriceptive_obs
    
    print(f"\nğŸ§  åˆ›å»ºç­–ç•¥ç½‘ç»œ...")
    print(f"  â€¢ æœ¬ä½“è§‚æµ‹ç»´åº¦: {env_cfg.env.num_propriceptive_obs}")
    print(f"  â€¢ ç‰¹æƒè§‚æµ‹ç»´åº¦: {env_cfg.env.num_privileged_obs}")
    print(f"  â€¢ åŠ¨ä½œç»´åº¦: {env_cfg.env.num_actions}")
    
    # åˆ›å»º actor-critic
    actor_critic = actor_critic_class(
        env_cfg.env.num_propriceptive_obs,
        env_cfg.env.num_privileged_obs,
        env_cfg.env.num_actions,
        **class_to_dict(train_cfg.policy)
    ).to('cpu')
    
    # åŠ è½½æƒé‡
    actor_critic.load_state_dict(loaded_dict['model_state_dict'])
    print("âœ“ æƒé‡åŠ è½½æˆåŠŸ")
    
    # æå– actor
    model = copy.deepcopy(actor_critic.actor).to("cpu")
    model.eval()
    
    print(f"\nğŸ“Š Actor ç½‘ç»œç»“æ„:")
    print(model)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path:
        onnx_path = output_path
    else:
        export_dir = os.path.join(ROOT_DIR, 'logs', train_cfg.runner.experiment_name, 'exported', 'policies')
        os.makedirs(export_dir, exist_ok=True)
        onnx_path = os.path.join(export_dir, "policy.onnx")
    
    os.makedirs(os.path.dirname(onnx_path), exist_ok=True)
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    dummy_input = torch.randn(1, env_cfg.env.num_propriceptive_obs)  # æ·»åŠ  batch ç»´åº¦
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹...")
    with torch.no_grad():
        output = model(dummy_input)
    print(f"âœ“ è¾“å…¥: {list(dummy_input.shape)} -> è¾“å‡º: {list(output.shape)}")
    
    # å¯¼å‡º ONNX
    print(f"\nğŸ”„ å¯¼å‡º ONNX: {onnx_path}")
    
    torch.onnx.export(
        model,
        dummy_input,
        onnx_path,
        verbose=False,
        input_names=["obs"],
        output_names=["actions"],
        export_params=True,
        opset_version=11,
        do_constant_folding=True,
        dynamic_axes={
            'obs': {0: 'batch_size'},
            'actions': {0: 'batch_size'}
        }
    )
    
    print(f"âœ… ONNX å¯¼å‡ºæˆåŠŸ: {onnx_path}")
    
    # å¯é€‰ï¼šè½¬æ¢ä¸º TensorRT engine
    if convert_engine:
        engine_path = onnx_path.replace(".onnx", ".engine")
        convert_onnx_to_engine(onnx_path, engine_path)
    
    return onnx_path


def convert_onnx_to_engine(onnx_path, engine_path, trtexec_path=None):
    """è½¬æ¢ ONNX ä¸º TensorRT engine"""
    
    if os.path.exists(engine_path):
        print(f"\nâš ï¸  Engine æ–‡ä»¶å·²å­˜åœ¨: {engine_path}")
        return
    
    # æŸ¥æ‰¾ trtexec
    if trtexec_path is None:
        common_paths = [
            "/home/bubble/ä¸‹è½½/TensorRT-8.6.1.6/targets/x86_64-linux-gnu/bin/trtexec",
            "/usr/src/tensorrt/bin/trtexec",
            "trtexec"
        ]
        for path in common_paths:
            if os.path.exists(path) or path == "trtexec":
                trtexec_path = path
                break
    
    if trtexec_path is None:
        print("\nâš ï¸  æœªæ‰¾åˆ° trtexecï¼Œè·³è¿‡ TensorRT è½¬æ¢")
        print("æç¤º: å¯ä»¥ç¨ååœ¨ Docker ä¸­è½¬æ¢")
        return
    
    command = [
        trtexec_path,
        f"--onnx={onnx_path}",
        f"--saveEngine={engine_path}",
        "--fp16"
    ]
    
    try:
        print(f"\nğŸ”„ è½¬æ¢ä¸º TensorRT engine...")
        subprocess.run(command, check=True)
        print(f"âœ… Engine ä¿å­˜æˆåŠŸ: {engine_path}")
    except subprocess.CalledProcessError as e:
        print(f"âŒ TensorRT è½¬æ¢å¤±è´¥: {e}")
    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ° trtexec: {trtexec_path}")


def main():
    # å…ˆè§£æå·²æœ‰å‚æ•°
    args = get_args()
    
    # æ‰‹åŠ¨è§£æé¢å¤–å‚æ•°
    import sys
    pt_path = None
    output_path = None
    convert_engine = False
    trtexec_path = None
    
    argv = sys.argv[1:]
    i = 0
    while i < len(argv):
        if argv[i] == '--pt_path' and i + 1 < len(argv):
            pt_path = argv[i + 1]
            i += 2
        elif argv[i] == '--output' and i + 1 < len(argv):
            output_path = argv[i + 1]
            i += 2
        elif argv[i] == '--to_engine':
            convert_engine = True
            i += 1
        elif argv[i] == '--trtexec_path' and i + 1 < len(argv):
            trtexec_path = argv[i + 1]
            i += 2
        else:
            i += 1
    
    # æ˜¾ç¤ºä½¿ç”¨çš„å‚æ•°
    if pt_path:
        print(f"ğŸ“Œ æŒ‡å®šçš„æ¨¡å‹è·¯å¾„: {pt_path}")
    if output_path:
        print(f"ğŸ“Œ è¾“å‡ºè·¯å¾„: {output_path}")
    if convert_engine:
        print(f"ğŸ“Œ å°†è½¬æ¢ä¸º TensorRT engine")
    
    # å¯¼å‡º
    export_policy_as_onnx(
        args,
        pt_path=pt_path,
        output_path=output_path,
        convert_engine=convert_engine
    )
    
    print("\n" + "=" * 70)
    print("âœ… å®Œæˆ!")
    print("=" * 70)


if __name__ == '__main__':
    main()
